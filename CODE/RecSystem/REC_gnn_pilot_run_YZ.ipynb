{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"REC_gnn-pilot-run_YZ.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["The codes in this notebook were tested on Google Colab with GPU.  "],"metadata":{"id":"dJ9Nx3UILbyr"}},{"cell_type":"markdown","source":["## Params"],"metadata":{"id":"ScIRGRbsual_"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RnpoJbKknkzK","executionInfo":{"status":"ok","timestamp":1658492860999,"user_tz":240,"elapsed":19276,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}},"outputId":"78a59b69-19f3-40e2-8737-400ffeb8706f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import torch\n","import torch.nn as nn\n","import random\n","import pickle\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["mydir_g = \"/content/gdrive/MyDrive/DS4A2022/cleaned_data_for_gnn\"\n"],"metadata":{"id":"dUclUwQ1uFZJ","executionInfo":{"status":"ok","timestamp":1658492872011,"user_tz":240,"elapsed":128,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Definitions"],"metadata":{"id":"WBaYLq3Dug-_"}},{"cell_type":"markdown","source":["### Data inputs"],"metadata":{"id":"JKPw4r-ouzsw"}},{"cell_type":"markdown","source":["- data: customer x item dataset (uid, iid, label_buy)\n","- u_items_list: user modeling in item-space, for each uid: (iid, label_buy)\n","- u_users_list: user modeling in user-user network space (cluster users by feature?), for each uid: (uid_neighbor)\n","- u_users_items_list: user modeling in neighbor's item space, for each uid: (for each neighbor_uid: (iid))\n","- i_users_list: item modeling in uer space, for each iid: (uid, label_buy)"],"metadata":{"id":"JRfIpwcrupbw"}},{"cell_type":"markdown","source":["### Graph data class"],"metadata":{"id":"HcfKsRiwu3EH"}},{"cell_type":"code","source":["# create torch dataset and preprocessing\n","class GraphDataset(Dataset):\n","    def __init__(self, data, u_items_list, u_user_list, u_users_items_list, i_users_list):\n","        self.data = data\n","        self.u_items_list = u_items_list\n","        self.u_users_list = u_user_list\n","        self.u_users_items_list = u_users_items_list\n","        self.i_users_list = i_users_list\n","        self.users = list(set(data.uid))\n","        self.items = list(set(data.iid))\n","\n","    def __getitem__(self, index):\n","        uid = self.data.iloc[index][0]\n","        iid = self.data.iloc[index][1]\n","        label = self.data.iloc[index][2]\n","        myidx = self.users.index(uid)\n","        u_items = self.u_items_list[myidx]\n","        u_users = self.u_users_list[myidx]\n","        u_users_items = self.u_users_items_list[myidx]\n","        myidx_i = self.items.index(iid)\n","        i_users = self.i_users_list[myidx_i]\n","\n","        return (uid, iid, label), u_items, u_users, u_users_items, i_users\n","\n","    def __len__(self):\n","        return len(self.data)"],"metadata":{"id":"c_hd-9zFukwk","executionInfo":{"status":"ok","timestamp":1658492878737,"user_tz":240,"elapsed":135,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Preprocess function"],"metadata":{"id":"AHoVOgoOvDdh"}},{"cell_type":"code","source":["truncate_len = 45\n","\n","def collate_fn(batch_data):\n","\n","    uids, iids, labels = [], [], []\n","    u_items, u_users, u_users_items, i_users = [], [], [], []\n","    u_items_len, u_users_len, i_users_len = [], [], []\n","\n","    for data, u_items_u, u_users_u, u_users_items_u, i_users_i in batch_data:\n","\n","        (uid, iid, label) = data\n","        uids.append(uid)\n","        iids.append(iid)\n","        labels.append(label)\n","\n","        # user-items\n","        if len(u_items_u) <= truncate_len:\n","            u_items.append(u_items_u)\n","        else:\n","            u_items.append(random.sample(u_items_u, truncate_len))\n","        u_items_len.append(min(len(u_items_u), truncate_len))\n","        \n","        # user-users and user-users-items\n","        if len(u_users_u) <= truncate_len:\n","            u_users.append(u_users_u)\n","            u_u_items = [] \n","            for uui in u_users_items_u:\n","                if len(uui) < truncate_len:\n","                    u_u_items.append(uui)\n","                else:\n","                    u_u_items.append(random.sample(uui, truncate_len))\n","            u_users_items.append(u_u_items)\n","        else:\n","            sample_index = random.sample(list(range(len(u_users_u))), truncate_len)\n","            u_users.append([u_users_u[si] for si in sample_index])\n","\n","            u_users_items_u_tr = [u_users_items_u[si] for si in sample_index]\n","            u_u_items = [] \n","            for uui in u_users_items_u_tr:\n","                if len(uui) < truncate_len:\n","                    u_u_items.append(uui)\n","                else:\n","                    u_u_items.append(random.sample(uui, truncate_len))\n","            u_users_items.append(u_u_items)\n","\n","        u_users_len.append(min(len(u_users_u), truncate_len))\t\n","\n","        # item-users\n","        if len(i_users_i) <= truncate_len:\n","            i_users.append(i_users_i)\n","        else:\n","            i_users.append(random.sample(i_users_i, truncate_len))\n","        i_users_len.append(min(len(i_users_i), truncate_len))\n","\n","    batch_size = len(batch_data)\n","\n","    # padding\n","    u_items_maxlen = max(u_items_len)\n","    u_users_maxlen = max(u_users_len)\n","    i_users_maxlen = max(i_users_len)\n","    \n","    u_item_pad = torch.zeros([batch_size, u_items_maxlen, 2], dtype=torch.long)\n","    for i, ui in enumerate(u_items):\n","        u_item_pad[i, :len(ui), :] = torch.LongTensor(ui)\n","    \n","    u_user_pad = torch.zeros([batch_size, u_users_maxlen], dtype=torch.long)\n","    for i, uu in enumerate(u_users):\n","        u_user_pad[i, :len(uu)] = torch.LongTensor(uu)\n","    \n","    u_user_item_pad = torch.zeros([batch_size, u_users_maxlen, u_items_maxlen, 2], dtype=torch.long)\n","    for i, uu_items in enumerate(u_users_items):\n","        for j, ui in enumerate(uu_items):\n","            u_user_item_pad[i, j, :len(ui), :] = torch.LongTensor(ui)\n","\n","    i_user_pad = torch.zeros([batch_size, i_users_maxlen, 2], dtype=torch.long)\n","    for i, iu in enumerate(i_users):\n","        i_user_pad[i, :len(iu), :] = torch.LongTensor(iu)\n","\n","    uids = torch.LongTensor(uids)\n","    iids = torch.LongTensor(iids)\n","    labels = torch.FloatTensor(labels)\n","\n","    return uids, iids, labels, u_item_pad, u_user_pad, u_user_item_pad, i_user_pad"],"metadata":{"id":"HtebvYkYu7ya","executionInfo":{"status":"ok","timestamp":1658492880025,"user_tz":240,"elapsed":112,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### Model classes"],"metadata":{"id":"MRlYqkwgve2g"}},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(MLP, self).__init__()\n","        self.mlp = nn.Sequential(\n","            nn.Linear(input_dim, input_dim//2, bias=True),\n","            nn.ReLU(),\n","            nn.Linear(input_dim//2, output_dim, bias=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.mlp(x)\n","\n","class Aggregator(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(Aggregator, self).__init__()\n","        self.mlp = nn.Sequential(\n","            nn.Linear(input_dim, output_dim, bias=True),\n","            nn.ReLU()\n","        )\n","\n","    def forward(self, x):\n","        return self.mlp(x)\n","\n","\n","class UserModel(nn.Module):\n","    def __init__(self, emb_dim, user_emb, item_emb, rating_emb):\n","        super(UserModel, self).__init__()\n","        self.emb_dim = emb_dim\n","        self.user_emb = user_emb\n","        self.item_emb = item_emb\n","        self.rating_emb = rating_emb\n","\n","        self.g_v = MLP(2*self.emb_dim, self.emb_dim)\n","        \n","        self.user_item_attn = MLP(2*self.emb_dim, 1)\n","        self.aggr_items = Aggregator(self.emb_dim, self.emb_dim)\n","\n","        self.user_user_attn = MLP(2*self.emb_dim, 1)\n","        self.aggr_neighbors = Aggregator(self.emb_dim, self.emb_dim)\n","\n","        self.mlp = nn.Sequential(\n","            nn.Linear(2*self.emb_dim, self.emb_dim, bias = True),\n","            nn.ReLU(),\n","            nn.Linear(self.emb_dim, self.emb_dim, bias = True),\n","            nn.ReLU(),\n","            nn.Linear(self.emb_dim, self.emb_dim, bias = True),\n","            nn.ReLU()\n","        )\n","\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.eps = 1e-10\n","\n","    def forward(self, uids, u_item_pad, u_user_pad, u_user_item_pad):\n","\n","        q_a = self.item_emb(u_item_pad[:,:,0])\n","        u_item_er = self.rating_emb(u_item_pad[:,:,1])\n","        x_ia = self.g_v(torch.cat([q_a, u_item_er], dim=2).view(-1, 2*self.emb_dim)).view(q_a.size())\n","        mask_u = torch.where(u_item_pad[:,:,0]>0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n","        p_i = mask_u.unsqueeze(2).expand_as(x_ia) * self.user_emb(uids).unsqueeze(1).expand_as(x_ia)\n","        alpha = self.user_item_attn(torch.cat([x_ia, p_i], dim=2).view(-1, 2*self.emb_dim)).view(mask_u.size())\n","        alpha = torch.exp(alpha)*mask_u\n","        alpha = alpha / (torch.sum(alpha, 1).unsqueeze(1).expand_as(alpha) + self.eps)\n","        h_iI = self.aggr_items(torch.sum(alpha.unsqueeze(2).expand_as(x_ia) * x_ia, 1))\n","\n","\n","        q_a_s = self.item_emb(u_user_item_pad[:,:,:,0])\n","        u_user_item_er = self.rating_emb(u_user_item_pad[:,:,:,1])\n","        x_ia_s = self.g_v(torch.cat([q_a_s, u_user_item_er], dim=2).view(-1, 2*self.emb_dim)).view(q_a_s.size())\n","        mask_s = torch.where(u_user_item_pad[:,:,:,0]>0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n","        p_i_s = mask_s.unsqueeze(3).expand_as(x_ia_s) * self.user_emb(u_user_pad).unsqueeze(2).expand_as(x_ia_s)\n","        alpha_s = self.user_item_attn(torch.cat([x_ia_s, p_i_s], dim=3).view(-1, 2*self.emb_dim)).view(mask_s.size())\n","        alpha_s = torch.exp(alpha_s)*mask_s\n","        alpha_s = alpha_s / (torch.sum(alpha_s, 2).unsqueeze(2).expand_as(alpha_s) + self.eps)\n","        h_oI_temp = torch.sum(alpha_s.unsqueeze(3).expand_as(x_ia_s) * x_ia_s, 2)\n","        h_oI = self.aggr_items(h_oI_temp.view(-1, self.emb_dim)).view(h_oI_temp.size())\n","        \n","        beta = self.user_user_attn(torch.cat([h_oI, self.user_emb(u_user_pad)], dim = 2).view(-1, 2 * self.emb_dim)).view(u_user_pad.size())\n","        mask_su = torch.where(u_user_pad > 0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n","        beta = torch.exp(beta) * mask_su\n","        beta = beta / (torch.sum(beta, 1).unsqueeze(1).expand_as(beta) + self.eps)\n","        h_iS = self.aggr_neighbors(torch.sum(beta.unsqueeze(2).expand_as(h_oI) * h_oI, 1))\n","\n","        h_i = self.mlp(torch.cat([h_iI, h_iS], dim = 1))\n","\n","        return h_i\n","\n","\n","class ItemModel(nn.Module):\n","    def __init__(self, emb_dim, user_emb, item_emb, rating_emb):\n","        super(ItemModel, self).__init__()\n","        self.emb_dim = emb_dim\n","        self.user_emb = user_emb\n","        self.item_emb = item_emb\n","        self.rating_emb = rating_emb\n","\n","        self.g_u = MLP(2*self.emb_dim, self.emb_dim)\n","\n","        self.item_users_attn = MLP(2*self.emb_dim, 1)\n","        self.aggr_users = Aggregator(self.emb_dim, self.emb_dim)\n","\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.eps = 1e-10\n","    \n","    def forward(self, iids, i_user_pad):\n","\n","        p_t = self.user_emb(i_user_pad[:,:,0])\n","        i_user_er = self.rating_emb(i_user_pad[:,:,1])\n","        mask_i = torch.where(i_user_pad[:,:,0] > 0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n","        f_jt = self.g_u(torch.cat([p_t, i_user_er], dim = 2).view(-1, 2 * self.emb_dim)).view(p_t.size())\n","        q_j = mask_i.unsqueeze(2).expand_as(f_jt) * self.item_emb(iids).unsqueeze(1).expand_as(f_jt)\n","        mu_jt = self.item_users_attn(torch.cat([f_jt, q_j], dim = 2).view(-1, 2 * self.emb_dim)).view(mask_i.size())\n","        mu_jt = torch.exp(mu_jt) * mask_i\n","        mu_jt = mu_jt / (torch.sum(mu_jt, 1).unsqueeze(1).expand_as(mu_jt) + self.eps)\n","        \n","        z_j = self.aggr_users(torch.sum(mu_jt.unsqueeze(2).expand_as(f_jt) * f_jt, 1))\n","\n","        return z_j\n","        \n","    \n","class GraphRec(nn.Module):\n","    def __init__(self, n_users, n_items, n_ratings, emb_dim = 64):\n","        super(GraphRec, self).__init__()\n","        self.n_users = n_users\n","        self.n_items = n_items\n","        self.n_ratings = n_ratings\n","        self.emb_dim = emb_dim\n","\n","        self.user_emb = nn.Embedding(self.n_users, self.emb_dim, padding_idx=0)\n","        self.item_emb = nn.Embedding(self.n_items, self.emb_dim, padding_idx=0)\n","        self.rating_emb = nn.Embedding(self.n_ratings, self.emb_dim, padding_idx=0)\n","\n","        self.user_model = UserModel(self.emb_dim, self.user_emb, self.item_emb, self.rating_emb)\n","        self.item_model = ItemModel(self.emb_dim, self.user_emb, self.item_emb, self.rating_emb)\n","\n","        self.mlp = nn.Sequential(\n","            nn.Linear(2*self.emb_dim, self.emb_dim, bias=True),\n","            nn.ReLU(),\n","            nn.Linear(self.emb_dim, self.emb_dim, bias=True),\n","            nn.ReLU(),\n","            nn.Linear(self.emb_dim, 1)\n","        )\n","\n","    def forward(self, uids, iids, u_item_pad, u_user_pad, u_user_item_pad, i_user_pad):\n","\n","        h_i = self.user_model(uids, u_item_pad, u_user_pad, u_user_item_pad)\n","        z_j = self.item_model(iids, i_user_pad)\n","\n","        r_ij = self.mlp(torch.cat([h_i, z_j], dim=1))\n","\n","        return r_ij"],"metadata":{"id":"6A3BQcnmvbPJ","executionInfo":{"status":"ok","timestamp":1658492881190,"user_tz":240,"elapsed":456,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Setup hyper-parameters"],"metadata":{"id":"GKeq_2OYvuyQ"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('device - ' + str(device))\n","batch_size = 128\n","embed_dim = 64\n","learning_rate = 0.001\n","n_epochs = 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dRSvLu0YvoK7","executionInfo":{"status":"ok","timestamp":1658492884093,"user_tz":240,"elapsed":136,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}},"outputId":"c5b3baee-c99e-4052-c217-2652d0afca8e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["device - cuda\n"]}]},{"cell_type":"markdown","source":["## Load input data"],"metadata":{"id":"p7XacH8XwDjA"}},{"cell_type":"code","source":["train_set =  pd.read_csv(mydir_g+\"/gnn_train.csv\")\n","valid_set =  pd.read_csv(mydir_g+\"/gnn_valid.csv\")\n","test_set =  pd.read_csv(mydir_g+\"/gnn_test.csv\")"],"metadata":{"id":"YLjBfibew7UI","executionInfo":{"status":"ok","timestamp":1658492893248,"user_tz":240,"elapsed":922,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["with open(mydir_g+'/u_items_list.pkl', 'rb') as f:\n","    u_items_list = pickle.load(f) \n","\n","with open(mydir_g+'/u_users_list.pkl', 'rb') as f:\n","    u_users_list = pickle.load(f) \n","\n","with open(mydir_g+'/u_users_items_list.pkl', 'rb') as f:\n","    u_users_items_list = pickle.load(f) \n","\n","with open(mydir_g+'/i_users_list.pkl', 'rb') as f:\n","    i_users_list = pickle.load(f) \n"],"metadata":{"id":"FU23NDGKwBdK","executionInfo":{"status":"ok","timestamp":1658492895978,"user_tz":240,"elapsed":1407,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["unique_count_df = pd.read_csv(mydir_g+\"/unique_counts.csv\")\n","(user_count, item_count, rate_count) = unique_count_df.iloc[0,:]\n","print(user_count,item_count, rate_count)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0fB6zsHBx_0p","executionInfo":{"status":"ok","timestamp":1658492896238,"user_tz":240,"elapsed":262,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}},"outputId":"4b160dfc-a453-4b94-886b-5e96b9ea2a7a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["471963 55717 2\n"]}]},{"cell_type":"code","source":["train_data = GraphDataset(train_set, u_items_list, u_users_list, u_users_items_list, i_users_list)\n","valid_data = GraphDataset(valid_set, u_items_list, u_users_list, u_users_items_list, i_users_list)\n","test_data = GraphDataset(test_set, u_items_list, u_users_list, u_users_items_list, i_users_list)"],"metadata":{"id":"5lMYyif7yHNA","executionInfo":{"status":"ok","timestamp":1658492896386,"user_tz":240,"elapsed":150,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True, collate_fn = collate_fn)\n","valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = False, collate_fn = collate_fn)\n","test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False, collate_fn = collate_fn)"],"metadata":{"id":"eeVHMp0LyPyy","executionInfo":{"status":"ok","timestamp":1658492896386,"user_tz":240,"elapsed":3,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Model setup"],"metadata":{"id":"cVY0hRg8ynSn"}},{"cell_type":"code","source":["model = GraphRec(user_count+1, item_count+1, rate_count+1, embed_dim).to(device)"],"metadata":{"id":"jQW13LFfyjtq","executionInfo":{"status":"ok","timestamp":1658492904951,"user_tz":240,"elapsed":6428,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.RMSprop(model.parameters(), learning_rate)\n","criterion = nn.MSELoss()\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 4, gamma = 0.1)"],"metadata":{"id":"CR9HEKGhyqsf","executionInfo":{"status":"ok","timestamp":1658492904952,"user_tz":240,"elapsed":3,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## Train model"],"metadata":{"id":"ViIzjg9fyx3H"}},{"cell_type":"markdown","source":["##### With age"],"metadata":{"id":"rY3k2LMSXlQ0"}},{"cell_type":"code","source":["# !mkdir -p trained_models_hm \n","mymodeldir = \"/content/gdrive/MyDrive/DS4A2022/trained_models_hm\""],"metadata":{"id":"Vy_smXc0yvpp","executionInfo":{"status":"ok","timestamp":1658493007161,"user_tz":240,"elapsed":117,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["for epoch in range(n_epochs):\n","\n","    # Training step\n","    model.train()\n","    s_loss = 0\n","    for i, (uids, iids, labels, u_items, u_users, u_users_items, i_users) in tqdm(enumerate(train_loader), total=len(train_loader)):\n","        uids = uids.to(device)\n","        iids = iids.to(device)\n","        labels = labels.to(device)\n","        u_items = u_items.to(device)\n","        u_users = u_users.to(device)\n","        u_users_items = u_users_items.to(device)\n","        i_users = i_users.to(device)\n","        \n","        optimizer.zero_grad()\n","        outputs = model(uids, iids, u_items, u_users, u_users_items, i_users)\n","        loss = criterion(outputs, labels.unsqueeze(1))\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        loss_val = loss.item()\n","        s_loss += loss_val\n","\n","        iter_num = epoch * len(train_loader) + i + 1\n","\n","    # Validate step\n","    model.eval()\n","    errors = []\n","    with torch.no_grad():\n","        for uids, iids, labels, u_items, u_users, u_users_items, i_users in tqdm(valid_loader):\n","            uids = uids.to(device)\n","            iids = iids.to(device)\n","            labels = labels.to(device)\n","            u_items = u_items.to(device)\n","            u_users = u_users.to(device)\n","            u_users_items = u_users_items.to(device)\n","            i_users = i_users.to(device)\n","            preds = model(uids, iids, u_items, u_users, u_users_items, i_users)\n","            error = torch.abs(preds.squeeze(1) - labels)\n","            errors.extend(error.data.cpu().numpy().tolist())\n","    \n","    mae = np.mean(errors)\n","    rmse = np.sqrt(np.mean(np.power(errors, 2)))\n","\n","    scheduler.step()\n","\n","    ckpt_dict = {\n","        'epoch': epoch + 1,\n","        'state_dict': model.state_dict(),\n","        'optimizer': optimizer.state_dict()\n","    }\n","\n","    torch.save(ckpt_dict, mymodeldir+'/latest_checkpoint.pth')\n","\n","    if epoch == 0:\n","        best_mae = mae\n","    elif mae < best_mae:\n","        best_mae = mae\n","        torch.save(ckpt_dict, mymodeldir+'/best_checkpoint_{}.pth'.format(embed_dim))\n","\n","    print('Epoch {} validation: MAE: {:.4f}, RMSE: {:.4f}, Best MAE: {:.4f}'.format(epoch+1, mae, rmse, best_mae))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o2UbDLpmy9o6","outputId":"19e3c2b9-39a9-4cd1-dc34-ba02ac658334","executionInfo":{"status":"ok","timestamp":1658500046804,"user_tz":240,"elapsed":7009990,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 993/993 [21:41<00:00,  1.31s/it]\n","100%|██████████| 284/284 [02:16<00:00,  2.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 validation: MAE: 0.4989, RMSE: 0.6654, Best MAE: 0.4989\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 993/993 [21:15<00:00,  1.28s/it]\n","100%|██████████| 284/284 [02:14<00:00,  2.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 validation: MAE: 0.5149, RMSE: 0.6655, Best MAE: 0.4989\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 993/993 [20:46<00:00,  1.25s/it]\n","100%|██████████| 284/284 [02:15<00:00,  2.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 validation: MAE: 0.4547, RMSE: 0.6422, Best MAE: 0.4547\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 993/993 [20:46<00:00,  1.26s/it]\n","100%|██████████| 284/284 [02:15<00:00,  2.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 validation: MAE: 0.4394, RMSE: 0.6409, Best MAE: 0.4394\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 993/993 [20:53<00:00,  1.26s/it]\n","100%|██████████| 284/284 [02:15<00:00,  2.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 validation: MAE: 0.4360, RMSE: 0.6390, Best MAE: 0.4360\n"]}]},{"cell_type":"code","source":["# copy to google drive\n","#!cp trained_models_hm/latest_checkpoint.pth \"/content/gdrive/MyDrive/DS4A_Capstone_local/trained_models_hm/latest_checkpoint.pth\"\n","#!cp trained_models_hm/best_checkpoint_64.pth \"/content/gdrive/MyDrive/DS4A_Capstone_local/trained_models_hm/best_checkpoint_64.pth\""],"metadata":{"id":"Nn74XPnOJxE8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Without age"],"metadata":{"id":"hc23kmC6X6_0"}},{"cell_type":"markdown","source":["## Test model"],"metadata":{"id":"7WmtLjiPBsZs"}},{"cell_type":"code","source":["embed_dim = 64\n","checkpoint = torch.load(mymodeldir+'/best_checkpoint_{}.pth'.format(embed_dim))\n","model = GraphRec(user_count+1, item_count+1, rate_count+1, embed_dim).to(device)\n","model.load_state_dict(checkpoint['state_dict'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJ4zReo4zETw","executionInfo":{"status":"ok","timestamp":1658501070644,"user_tz":240,"elapsed":762,"user":{"displayName":"yvonne zhuang","userId":"16653237438804765281"}},"outputId":"d2bc11b2-e716-43fb-df0e-cc8de9d64bee"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["model.eval()\n","test_errors = []\n","with torch.no_grad():\n","    for uids, iids, labels, u_items, u_users, u_users_items, i_users in tqdm(test_loader):\n","        uids = uids.to(device)\n","        iids = iids.to(device)\n","        labels = labels.to(device)\n","        u_items = u_items.to(device)\n","        u_users = u_users.to(device)\n","        u_users_items = u_users_items.to(device)\n","        i_users = i_users.to(device)\n","        preds = model(uids, iids, u_items, u_users, u_users_items, i_users)\n","        error = torch.abs(preds.squeeze(1) - labels)\n","        test_errors.extend(error.data.cpu().numpy().tolist())\n","\n","test_mae = np.mean(test_errors)\n","test_rmse = np.sqrt(np.mean(np.power(test_errors, 2)))\n","print('Test: MAE: {:.4f}, RMSE: {:.4f}'.format(test_mae, test_rmse))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WIaesixAB4xr","executionInfo":{"status":"ok","timestamp":1657994522784,"user_tz":240,"elapsed":46609,"user":{"displayName":"Yongwen Zhuang","userId":"05506063450855208596"}},"outputId":"dcc196e9-95fd-478a-eee4-77349ad29792"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 142/142 [00:45<00:00,  3.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Test: MAE: 0.4672, RMSE: 0.6350\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"WXToUh-jK_gY"},"execution_count":null,"outputs":[]}]}